{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxJDE8+nVPYCg1G0rzmMlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyeonb/AI_lab_baesuyeon/blob/main/week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "model = bundle.get_model()\n",
        "labels = bundle.get_labels()\n",
        "\n",
        "def speech_to_text(audio_file):\n",
        "    \"\"\"음성 파일을 텍스트로 변환\"\"\"\n",
        "    # 오디오 파일 로드\n",
        "    waveform, sr = torchaudio.load(audio_file)\n",
        "\n",
        "    # 샘플레이트 맞추기 (16kHz)\n",
        "    if sr != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
        "\n",
        "    # Mono로 변환\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    # 모델 추론\n",
        "    with torch.inference_mode():\n",
        "        emissions, _ = model(waveform)\n",
        "\n",
        "    # Greedy decoding\n",
        "    indices = torch.argmax(emissions, dim=-1)[0]\n",
        "    indices = torch.unique_consecutive(indices, dim=-1)\n",
        "    indices = [i for i in indices if i != 0]  # blank 토큰 제거\n",
        "    transcript = ''.join([labels[i] for i in indices])\n",
        "\n",
        "    return transcript\n",
        "\n",
        "# ==================== 사용 예시 ====================\n",
        "if __name__ == \"__main__\":\n",
        "    # 오디오 파일 경로\n",
        "    audio_file = \"week4_data.mp3\"\n",
        "\n",
        "    try:\n",
        "        # STT 실행\n",
        "        result = speech_to_text(audio_file)\n",
        "        print(f\"인식 결과: {result}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"파일을 찾을 수 없습니다: {audio_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"에러 발생: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm1gfO1avQKr",
        "outputId": "5f835a1e-e17b-4da5-cf80-b17894a942dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 360M/360M [00:00<00:00, 391MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인식 결과: LADIES|AND|GENTLEMEN|WELCOME|TO|THE|NATIONAL|MENIOL|CENTRE|THE|PERFORMANCE|WILL|BEGIN|SHORTLY|PLEASE|TURN|OFF|ANY|SELPHONES|AND|KEEP|IN|MIND|THE|RECORDING|OR|TAKING|PHOTOGRAPHS|OF|THE|PERFORMANCE|IS|NOT|PERMITTED|WITHOUT|AGREEMENT|FOR|YOUR|SAFETY|PLEASE|REFRAIN|FROM|CHANGING|SEATS|DURING|THE|SHOW|AND|LOCATE|THE|EMERGENCY|EXIT|AND|ESCAPE|ROOT|NEAREST|TO|YOU|\n"
          ]
        }
      ]
    }
  ]
}